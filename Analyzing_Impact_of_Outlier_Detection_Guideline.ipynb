{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN68vYqXKmnHYEhEd41wx7S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dajley/-Analyzing-Impact-of-Outlier-Detection-Guideline/blob/main/Analyzing_Impact_of_Outlier_Detection_Guideline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Analyzing Impact of Outlier Detection\n",
        "on Predictive Performance of ML Models**\n",
        "\n",
        "• Identify data distribution (normal, skewed,\n",
        "etc.,)\n",
        "\n",
        "• Detect & Replace outliers (IQR, Z-Score)\n",
        "\n",
        "• Build ML Models (LR, SVR, etc.,)\n",
        "\n",
        "• Evaluate Model performance with and\n",
        "without outliers (R2 score, MAE, RMSE, MSE)\n"
      ],
      "metadata": {
        "id": "yg-vVh9BITWs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Identifying the distribution of your data** is a key step in exploratory data analysis (EDA), especially when you're preparing for outlier detection, feature engineering, or model selection. Identifying the distribution of your data involves understanding the underlying shape and characteristics of its frequency distribution."
      ],
      "metadata": {
        "id": "ozo7Gxv9PQT3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How to Identify Data's Distribution:\n",
        "\n",
        "*   Descriptive Statistics\n",
        "    (Mean, Median, Standard Deviation, Skewness, and Kurtosis)\n",
        "\n",
        "*   Visualization Techniques\n",
        "*   Interpretation\n",
        "*   Statistical Tests\n",
        "*   Comparisons and Considerations\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YScDtDKUPT62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For agriculteral dataset giving crop yield based off certain features:\n",
        "\n",
        "\n",
        "*   Understand each feature (Catergorical variables vs. Numberical variables and Target variable)\n",
        "*   Explore Numerical Distributions\n",
        "*   Check for Skewed Distributions\n",
        "*   Use Boxplot for Outlier Detection\n",
        "*   Visualize Yield by Category\n",
        "*   Check for Relationships Between Inputs\n",
        "*   Modeling Implication Tips\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jiwKc71zSDIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To identify the data distribution of an agriculture dataset with crop yield as the target and several input features (e.g., rainfall, temperature, soil quality, fertilizer use, etc.), you’ll want to combine statistical analysis and visualizations. Here's a structured approach:\n",
        "\n",
        "**Understand the Dataset**\n",
        "Identify target and features: Crop yield is your target variable, and the rest are features.\n",
        "\n",
        "Feature types: Determine which features are numerical, categorical, or ordinal.\n",
        "\n",
        "**Visualize Distributions**\n",
        "Use plots to get an intuitive understanding of the data distributions.\n",
        "\n",
        "For Numerical Features:\n",
        "Histogram or KDE (Kernel Density Estimation) plot\n",
        "\n",
        "Shows how data points are distributed.\n",
        "\n",
        "Helps identify skewness, modality, and potential outliers.\n",
        "\n",
        "Boxplot\n",
        "\n",
        "Highlights the spread, median, and outliers.\n",
        "\n",
        "For Categorical Features:\n",
        "Bar plots to see frequency of categories.\n",
        "\n",
        "For Crop Yield:\n",
        "Histogram/KDE: Understand its spread and shape.\n",
        "\n",
        "Q-Q Plot: To test for normality visually.\n",
        "\n",
        "Boxplot grouped by categorical features (e.g., region or crop type).\n",
        "\n",
        "**Statistical Summaries**\n",
        "df.describe() for numerical features.\n",
        "\n",
        "Use .value_counts() or pd.crosstab() for categorical ones.\n",
        "\n",
        "Skewness and kurtosis to understand asymmetry and peakness.\n",
        "\n",
        "**Distribution Fit Tests**\n",
        "Check if the target (crop yield) follows a common statistical distribution:\n",
        "\n",
        "Shapiro-Wilk Test\n",
        "\n",
        "Kolmogorov-Smirnov Test\n",
        "\n",
        "Anderson-Darling Test\n",
        "\n",
        "These test the null hypothesis that the data is normally distributed.\n",
        "\n",
        "**Correlation & Relationship**s\n",
        "Understand how features relate to crop yield:\n",
        "\n",
        "Correlation matrix (.corr()) for numeric features.\n",
        "\n",
        "Scatter plots: Feature vs Crop Yield.\n",
        "\n",
        "Pairplots (e.g., using Seaborn) for multivariate visualization.\n",
        "\n",
        "**Feature Interactions & Multivariate Distributions**\n",
        "Use pairplot or multidimensional KDE plots.\n",
        "\n",
        "Apply PCA or t-SNE to reduce dimensions and observe structure in 2D.\n",
        "\n"
      ],
      "metadata": {
        "id": "B-KMUGDXovlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Histogram and KDE\n",
        "sns.histplot(df['crop_yield'], kde=True)\n",
        "\n",
        "# Boxplot\n",
        "sns.boxplot(x='region', y='crop_yield', data=df)\n",
        "\n",
        "# Q-Q plot\n",
        "stats.probplot(df['crop_yield'], dist=\"norm\", plot=plt)\n",
        "\n",
        "# Shapiro test\n",
        "stat, p = stats.shapiro(df['crop_yield'])\n",
        "print(f'Shapiro-Wilk Test: stat={stat:.3f}, p={p:.3f}')\n"
      ],
      "metadata": {
        "id": "a_Vj9EuKpHwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By the end of this process, you should know:\n",
        "\n",
        "Is your data normally distributed?\n",
        "\n",
        "Are there any outliers?\n",
        "\n",
        "How do features relate to crop yield?\n",
        "\n",
        "Is data transformation (e.g., log-transform) needed?"
      ],
      "metadata": {
        "id": "lDk3sSL-pvmE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Detect outliers (using IQR or Z-score)**\n",
        "Flag the outliers but don’t remove them yet — instead, keep track of which rows have outliers.\n",
        "\n",
        "**Create three versions of the dataset**\n",
        "*   Dataset A (Remove outliers): Drop rows with outliers.\n",
        "*   Dataset B (Median Imputation): Replace outlier values with the median of that feature.\n",
        "*   Dataset C (Mean Imputation): Replace outlier values with the mean of that feature.\n",
        "\n",
        "**Train ML models on each dataset**\n",
        "Split each dataset into train and test sets (same random seed), train the same ML model (e.g., Random Forest), and evaluate performance.\n",
        "\n",
        "**Compare results**\n",
        "Evaluate RMSE, MAE, and R² for each dataset and analyze which outlier handling method works best."
      ],
      "metadata": {
        "id": "2qfmnbNlcLbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('crop_yield_data.csv')\n",
        "X = df.drop(columns=['crop_yield'])\n",
        "y = df['crop_yield']\n",
        "\n",
        "# --- 1. Detect Outliers using IQR ---\n",
        "Q1 = X.quantile(0.25)\n",
        "Q3 = X.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Create a mask where True means the value is an outlier\n",
        "outlier_mask = ((X < lower_bound) | (X > upper_bound))\n",
        "\n",
        "# --- 2. Create datasets ---\n",
        "\n",
        "# Dataset A: Remove rows with any outlier\n",
        "rows_to_remove = outlier_mask.any(axis=1)\n",
        "X_remove = X.loc[~rows_to_remove]\n",
        "y_remove = y.loc[~rows_to_remove]\n",
        "\n",
        "# Dataset B: Replace outliers with median\n",
        "X_median = X.copy()\n",
        "for col in X.columns:\n",
        "    median_val = X[col].median()\n",
        "    X_median.loc[outlier_mask[col], col] = median_val\n",
        "\n",
        "# Dataset C: Replace outliers with mean\n",
        "X_mean = X.copy()\n",
        "for col in X.columns:\n",
        "    mean_val = X[col].mean()\n",
        "    X_mean.loc[outlier_mask[col], col] = mean_val\n",
        "\n",
        "# --- 3. Train-test split (same random state for comparability) ---\n",
        "def split_data(X, y):\n",
        "    return train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "X_train_orig, X_test_orig, y_train_orig, y_test_orig = split_data(X, y)\n",
        "X_train_remove, X_test_remove, y_train_remove, y_test_remove = split_data(X_remove, y_remove)\n",
        "X_train_median, X_test_median, y_train_median, y_test_median = split_data(X_median, y)\n",
        "X_train_mean, X_test_mean, y_train_mean, y_test_mean = split_data(X_mean, y)\n",
        "\n",
        "# --- 4. Train and evaluate ---\n",
        "def train_evaluate(X_train, y_train, X_test, y_test):\n",
        "    model = RandomForestRegressor(random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
        "    mae = mean_absolute_error(y_test, preds)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    return rmse, mae, r2\n",
        "\n",
        "results = {}\n",
        "results['Original'] = train_evaluate(X_train_orig, y_train_orig, X_test_orig, y_test_orig)\n",
        "results['Remove Outliers'] = train_evaluate(X_train_remove, y_train_remove, X_test_remove, y_test_remove)\n",
        "results['Median Imputation'] = train_evaluate(X_train_median, y_train_median, X_test_median, y_test_median)\n",
        "results['Mean Imputation'] = train_evaluate(X_train_mean, y_train_mean, X_test_mean, y_test_mean)\n",
        "\n",
        "# --- 5. Print results ---\n",
        "for method, metrics in results.items():\n",
        "    print(f\"{method}: RMSE={metrics[0]:.3f}, MAE={metrics[1]:.3f}, R2={metrics[2]:.3f}\")\n"
      ],
      "metadata": {
        "id": "iYPYJJqBQEqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obsFGQfExk2B"
      },
      "outputs": [],
      "source": []
    }
  ]
}